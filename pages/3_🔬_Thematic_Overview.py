"""
Thematic Overview - High-level exploration of OVGU's research portfolio.

Sections:
1. Interactive Treemap (Domain ‚Üí Field ‚Üí Subfield)
2. Domains table + FWCI boxplots
3. Fields table + FWCI boxplots
4. Subfields table
5. Topics table (OpenAlex)
6. Topics table (Topic Modeling) + Heatmap
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go

from lib.helpers import (
    DOMAIN_ORDER,
    DOMAIN_COLORS,
    DOMAIN_EMOJI,
    get_domain_id_to_name,
    get_field_id_to_name,
    get_field_id_to_domain_id,
    get_subfield_id_to_name,
    get_subfield_id_to_domain_id,
    get_field_order_by_domain,
    parse_pipe_float_list,
    render_domain_legend,
)

from lib.data_cache import (
    load_thematic_overview,
    load_treemap_hierarchy,
    load_tm_labels,
)

# =============================================================================
# Page config
# =============================================================================
st.set_page_config(
    page_title="Thematic Overview | OVGU Bibliometrics",
    page_icon="üî¨",
    layout="wide",
)

st.title("üî¨ Thematic Overview")
st.markdown("Explore OVGU's research portfolio across OpenAlex thematic taxonomies and bottom-up topics.")

# =============================================================================
# Load data
# =============================================================================

df_overview = load_thematic_overview()
df_treemap_raw = load_treemap_hierarchy()
df_tm_labels = load_tm_labels()

# Lookups
domain_id2name = get_domain_id_to_name()
field_id2name = get_field_id_to_name()
field_id2domain = get_field_id_to_domain_id()
subfield_id2name = get_subfield_id_to_name()
subfield_id2domain = get_subfield_id_to_domain_id()

# =============================================================================
# Helper functions
# =============================================================================
def get_domain_name_from_id(dom_id):
    try:
        return domain_id2name.get(int(dom_id), "Other")
    except (ValueError, TypeError):
        return "Other"

def get_domain_emoji(dom_name):
    return DOMAIN_EMOJI.get(dom_name, "‚¨ú")

def format_pct(val):
    if pd.isna(val):
        return "‚Äî"
    try:
        return f"{float(val)*100:.1f}%"
    except (ValueError, TypeError):
        return "‚Äî"

def format_cagr(val):
    if pd.isna(val):
        return "‚Äî"
    try:
        val = float(val)
        arrow = "‚Üë" if val > 0 else ("‚Üì" if val < 0 else "‚Üí")
        return f"{arrow} {val*100:+.1f}%"
    except (ValueError, TypeError):
        return "‚Äî"

def format_si(val):
    """Format Specialization Index values."""
    if pd.isna(val):
        return "‚Äî"
    try:
        return f"{float(val):.2f}"
    except (ValueError, TypeError):
        return "‚Äî"

def format_dominance(val):
    """Format Dominance values (multiply by 100, 4 decimals)."""
    if pd.isna(val):
        return "‚Äî"
    try:
        return f"{float(val)*100:.4f}%"
    except (ValueError, TypeError):
        return "‚Äî"

def parse_fwci_boxplot(blob):
    if pd.isna(blob) or not str(blob).strip():
        return None
    vals = parse_pipe_float_list(blob)
    if len(vals) < 7:
        return None
    return {"p0": vals[0], "p10": vals[1], "p25": vals[2], "p50": vals[3], 
            "p75": vals[4], "p90": vals[5], "p100": vals[6]}

def parse_pubs_per_domain(blob):
    if pd.isna(blob) or not str(blob).strip():
        return {}
    result = {}
    for part in str(blob).split("|"):
        if ":" in part:
            k, v = part.split(":", 1)
            try:
                result[int(k)] = int(v)
            except ValueError:
                pass
    return result

# =============================================================================
# Section 1: Interactive Treemap
# =============================================================================
st.markdown("---")
st.markdown("## üìä Research Portfolio Treemap")

st.markdown("""
**How to read this chart**: Each rectangle represents a thematic area. Size reflects publication volume.
Click to drill down from domains ‚Üí fields ‚Üí subfields. Use the breadcrumb trail to navigate back.
""")

# Prepare treemap data
df_treemap = df_treemap_raw.copy()

# Color metric selector (only available metrics)
color_metric = st.selectbox(
    "Color by:",
    ["fwci_median", "pct_international"],
    format_func=lambda x: {
        "fwci_median": "Median FWCI (citation impact)",
        "pct_international": "% International collaborations",
    }.get(x, x)
)

# Build treemap with custom color scale for FWCI
if color_metric == "fwci_median":
    fig_treemap = px.treemap(
        df_treemap,
        ids="id",
        names="name",
        parents="parent_id",
        values="pubs",
        color="fwci_median",
        color_continuous_scale=[
            [0.0, "#EC8773"],    # Red for 0
            [0.5, "#F4D570"],    # Grey for 1
            [1.0, "#60CCAA"],    # Green for 2+
        ],
        range_color=[0, 2],
    )
else:
    fig_treemap = px.treemap(
        df_treemap,
        ids="id",
        names="name",
        parents="parent_id",
        values="pubs",
        color=color_metric,
        color_continuous_scale="Blues",
    )

# Update hover template
fig_treemap.update_traces(
    customdata=np.stack([
        df_treemap["pubs"],
        df_treemap["fwci_median"],
        df_treemap["pct_international"] * 100,
    ], axis=-1),
    hovertemplate="<b>%{label}</b><br>" +
                  "Publications: %{customdata[0]:,}<br>" +
                  "FWCI median: %{customdata[1]:.2f}<br>" +
                  "International: %{customdata[2]:.1f}%<extra></extra>"
)

fig_treemap.update_layout(
    margin=dict(t=30, l=10, r=10, b=10),
    height=600,
)

st.plotly_chart(fig_treemap, use_container_width=True)

# =============================================================================
# Section 2: Domains
# =============================================================================
st.markdown("---")
st.markdown("## üåê Domains")
st.markdown("""
Domains represent the highest level of thematic classification in OpenAlex. 
All research output is distributed across four broad domains: Life Sciences, Social Sciences, Physical Sciences, and Health Sciences.
""")

render_domain_legend()

df_domains = df_overview[df_overview["level"] == "domain"].copy()
df_domains["domain_id"] = df_domains["id"].astype(int)
df_domains = df_domains.sort_values("domain_id", key=lambda x: x.map({d: i for i, d in enumerate(DOMAIN_ORDER)}))

st.markdown("### Overview by Domain")

# Build display table
domain_table = []
for _, row in df_domains.iterrows():
    dom_name = row["name"]
    domain_table.append({
        "Domain": f"{get_domain_emoji(dom_name)} {dom_name}",
        "Pubs": int(row["pubs_total"]),
        "% Total": format_pct(row.get("pubs_pct_of_um", row.get("pubs_pct_of_ul"))),
        "% Int'l": format_pct(row.get("pct_international")),
        "% Company": format_pct(row.get("pct_company")),
        "% SDG": format_pct(row.get("pct_sdg")),
        "CAGR": format_cagr(row.get("cagr_2020_2024", row.get("cagr_2019_2023"))),
    })

df_domain_display = pd.DataFrame(domain_table)
st.dataframe(
    df_domain_display,
    use_container_width=True,
    hide_index=True,
)

# FWCI Distribution boxplots
st.markdown("### FWCI Distribution by Domain")

use_extreme = st.toggle("Include extreme values (p0, p100)", value=False, key="domain_extreme")

boxplot_data = []
for _, row in df_domains.iterrows():
    bp = parse_fwci_boxplot(row.get("fwci_boxplot"))
    if bp:
        dom_name = row["name"]
        boxplot_data.append({
            "domain": dom_name,
            "domain_id": row["domain_id"],
            "color": DOMAIN_COLORS.get(dom_name, "#7f7f7f"),
            "count": int(row["pubs_total"]),
            **bp
        })

if boxplot_data:
    boxplot_data = sorted(boxplot_data, key=lambda x: DOMAIN_ORDER.index(x["domain_id"]) if x["domain_id"] in DOMAIN_ORDER else 99)
    
    fig_box = go.Figure()
    
    for i, item in enumerate(boxplot_data):
        if use_extreme:
            lower, upper = item["p0"], item["p100"]
        else:
            lower, upper = item["p10"], item["p90"]
        
        fig_box.add_trace(go.Box(
            x=[item["domain"]],
            lowerfence=[lower],
            q1=[item["p25"]],
            median=[item["p50"]],
            q3=[item["p75"]],
            upperfence=[upper],
            marker_color=item["color"],
            fillcolor=item["color"],
            line=dict(color=item["color"]),
            boxpoints=False,
            name=item["domain"],
            showlegend=False,
        ))
        
        fig_box.add_annotation(
            x=item["domain"],
            y=-0.15,
            yref="paper",
            text=f"n={item['count']:,}",
            showarrow=False,
            font=dict(size=11, color="#666"),
        )
    
    fig_box.update_layout(
        height=350,
        margin=dict(t=30, l=50, r=30, b=60),
        yaxis_title="FWCI",
        xaxis_title="",
    )
    st.plotly_chart(fig_box, use_container_width=True)

# =============================================================================
# Section 3: Fields
# =============================================================================
st.markdown("---")
st.markdown("## üìö Fields")
st.markdown("""
Fields are the second level of the OpenAlex taxonomy, grouping related disciplines within each domain. 
This view highlights the institution's disciplinary strengths and citation performance across 26 fields.
""")
render_domain_legend()

df_fields = df_overview[df_overview["level"] == "field"].copy()
df_fields["field_id"] = df_fields["id"].astype(int)
df_fields["domain_id"] = df_fields["parent_id"].astype(int)
df_fields["domain_name"] = df_fields["domain_id"].map(domain_id2name)

df_fields_table = df_fields.sort_values("pubs_total", ascending=False)

st.markdown("### Overview by Field")

field_table = []
for _, row in df_fields_table.iterrows():
    dom_name = row["domain_name"]
    field_table.append({
        "": get_domain_emoji(dom_name),
        "Field": row["name"],
        "Pubs": int(row["pubs_total"]),
        "% Total": format_pct(row.get("pubs_pct_of_um", row.get("pubs_pct_of_ul"))),
        "SI Germany": format_si(row.get("si_germany")),
        "SI Europe": format_si(row.get("si_europe")),
        "NCI": format_si(row.get("nci")),
        "PP Top 10%": format_pct(row.get("PP_in_top_10_percent")),
        "Dom. Top 10%": format_dominance(row.get("dominance_in_top_10_percent")),
        "PP Top 1%": format_pct(row.get("PP_in_top_1_percent")),
        "Dom. Top 1%": format_dominance(row.get("dominance_in_top_1_percent")),
        "% Int'l": format_pct(row.get("pct_international")),
        "% Company": format_pct(row.get("pct_company")),
        "CAGR": format_cagr(row.get("cagr_2020_2024", row.get("cagr_2019_2023"))),
    })

df_field_display = pd.DataFrame(field_table)
st.dataframe(
    df_field_display,
    use_container_width=True,
    hide_index=True,
    height=500,
)

# =============================================================================
# FWCI Distribution by Field
# =============================================================================
st.markdown("### FWCI Distribution by Field")

st.markdown("""
This chart shows the distribution of Field-Weighted Citation Impact (FWCI) across fields.
By default, extreme values are hidden (showing percentiles 10-90) to facilitate comparison between fields.
Toggle the option below to include the full range (min to max).
""")

use_extreme_fields = st.toggle("Include extreme values (p0, p100)", value=False, key="field_extreme")

# Sort by domain order for boxplot
field_order = get_field_order_by_domain()
df_fields_sorted = df_fields.copy()
df_fields_sorted["sort_order"] = df_fields_sorted["field_id"].map({fid: i for i, fid in enumerate(field_order)})
df_fields_sorted = df_fields_sorted.sort_values("sort_order")

boxplot_data_fields = []
for _, row in df_fields_sorted.iterrows():
    bp = parse_fwci_boxplot(row["fwci_boxplot"])
    if bp and row["pubs_total"] > 0:
        field_id = row["field_id"]
        dom_id = field_id2domain.get(field_id, 0)
        dom_name = domain_id2name.get(dom_id, "Other")
        boxplot_data_fields.append({
            "field": row["name"],
            "field_id": field_id,
            "color": DOMAIN_COLORS.get(dom_name, "#7f7f7f"),
            "count": int(row["pubs_total"]),
            **bp
        })

if boxplot_data_fields:
    fig_box_fields = go.Figure()
    
    for item in boxplot_data_fields:
        if use_extreme_fields:
            lower, upper = item["p0"], item["p100"]
            range_label = "min-max"
        else:
            lower, upper = item["p10"], item["p90"]
            range_label = "p10-p90"
        
        fig_box_fields.add_trace(go.Box(
            x=[item["field"]],
            lowerfence=[lower],
            q1=[item["p25"]],
            median=[item["p50"]],
            q3=[item["p75"]],
            upperfence=[upper],
            marker_color=item["color"],
            fillcolor=item["color"],
            line=dict(color=item["color"]),
            boxpoints=False,
            name=f"{item['field']} (n={item['count']:,})",
            showlegend=False,
        ))
    
    # Add count annotations (straight orientation, no "n=" prefix)
    for i, item in enumerate(boxplot_data_fields):
        fig_box_fields.add_annotation(
            x=item["field"],
            y=-0.03,
            yref="paper",
            text=f"{item['count']:,}",
            showarrow=False,
            font=dict(size=9, color="#666"),
            textangle=0,
        )
    
    fig_box_fields.update_layout(
        height=500,
        margin=dict(t=30, l=50, r=30, b=160),
        yaxis_title="FWCI",
        xaxis_title="",
        xaxis_tickangle=-45,
        xaxis=dict(
            tickfont=dict(size=10),
        ),
        hoverlabel=dict(
            bgcolor="white",
            font_size=12,
            font_family="Arial",
        ),
    )
    st.plotly_chart(fig_box_fields, use_container_width=True)

# =============================================================================
# Section 4: Subfields
# =============================================================================
st.markdown("---")
st.markdown("## üìñ Subfields")
st.markdown("""
Subfields provide finer granularity, breaking down each field into more specific research areas. 
Use the filters below to explore subfields by domain or search for specific topics.
""")
render_domain_legend()

df_subfields = df_overview[df_overview["level"] == "subfield"].copy()
df_subfields["subfield_id"] = df_subfields["id"].astype(int)
df_subfields["field_id"] = df_subfields["parent_id"].astype(int)
df_subfields["field_name"] = df_subfields["field_id"].map(field_id2name)
df_subfields["domain_id"] = df_subfields["subfield_id"].map(subfield_id2domain)
df_subfields["domain_name"] = df_subfields["domain_id"].map(domain_id2name)

col_filter1, col_filter2 = st.columns(2)
with col_filter1:
    domain_filter = st.multiselect(
        "Filter by domain:",
        options=list(domain_id2name.values()),
        default=[],
        key="subfield_domain_filter"
    )
with col_filter2:
    search_subfield = st.text_input("Search subfield:", "", key="subfield_search")

df_subfields_filtered = df_subfields.copy()
if domain_filter:
    df_subfields_filtered = df_subfields_filtered[df_subfields_filtered["domain_name"].isin(domain_filter)]
if search_subfield:
    df_subfields_filtered = df_subfields_filtered[
        df_subfields_filtered["name"].str.lower().str.contains(search_subfield.lower(), na=False)
    ]

df_subfields_filtered = df_subfields_filtered.sort_values("pubs_total", ascending=False)

subfield_table = []
for _, row in df_subfields_filtered.iterrows():
    dom_name = row["domain_name"] if pd.notna(row["domain_name"]) else "Other"
    subfield_table.append({
        "": get_domain_emoji(dom_name),
        "Subfield": row["name"],
        "Field": row["field_name"] if pd.notna(row["field_name"]) else "",
        "Pubs": int(row["pubs_total"]),
        "% Total": format_pct(row.get("pubs_pct_of_um", row.get("pubs_pct_of_ul"))),
        "% Int'l": format_pct(row.get("pct_international")),
        "% SDG": format_pct(row.get("pct_sdg")),
        "CAGR": format_cagr(row.get("cagr_2020_2024", row.get("cagr_2019_2023"))),
    })

df_subfield_display = pd.DataFrame(subfield_table)
st.dataframe(
    df_subfield_display,
    use_container_width=True,
    hide_index=True,
    height=400,
)
st.caption(f"Showing {len(subfield_table)} subfields")

# =============================================================================
# Section 5: Topics (OpenAlex)
# =============================================================================
st.markdown("---")
st.markdown("## üè∑Ô∏è Topics (OpenAlex)")
st.markdown("""
Topics are the most granular level of the OpenAlex taxonomy, representing specific research areas within subfields.
Each publication is assigned to a single primary topic based on its content. Use the filters to explore the top 200 topics by volume.
""")
render_domain_legend()

df_topics = df_overview[df_overview["level"] == "oa_topic"].copy()
df_topics["topic_id"] = df_topics["id"]
df_topics["subfield_id"] = pd.to_numeric(df_topics["parent_id"], errors="coerce").astype("Int64")
df_topics["subfield_name"] = df_topics["subfield_id"].map(subfield_id2name)
df_topics["domain_id"] = df_topics["subfield_id"].map(subfield_id2domain)
df_topics["domain_name"] = df_topics["domain_id"].map(domain_id2name)

col_filter1, col_filter2 = st.columns(2)
with col_filter1:
    domain_filter_topics = st.multiselect(
        "Filter by domain:",
        options=list(domain_id2name.values()),
        default=[],
        key="topic_domain_filter"
    )
with col_filter2:
    search_topic = st.text_input("Search topic:", "", key="topic_search")

df_topics_filtered = df_topics.copy()
if domain_filter_topics:
    df_topics_filtered = df_topics_filtered[df_topics_filtered["domain_name"].isin(domain_filter_topics)]
if search_topic:
    df_topics_filtered = df_topics_filtered[
        df_topics_filtered["name"].str.lower().str.contains(search_topic.lower(), na=False)
    ]

df_topics_filtered = df_topics_filtered.sort_values("pubs_total", ascending=False).head(200)

topic_table = []
for _, row in df_topics_filtered.iterrows():
    dom_name = row["domain_name"] if pd.notna(row["domain_name"]) else "Other"
    topic_table.append({
        "": get_domain_emoji(dom_name),
        "Topic": row["name"],
        "Subfield": row["subfield_name"] if pd.notna(row["subfield_name"]) else "",
        "Pubs": int(row["pubs_total"]),
        "% Total": format_pct(row.get("pubs_pct_of_um", row.get("pubs_pct_of_ul"))),
        "% Int'l": format_pct(row.get("pct_international")),
        "% SDG": format_pct(row.get("pct_sdg")),
        "CAGR": format_cagr(row.get("cagr_2020_2024", row.get("cagr_2019_2023"))),
    })

df_topic_display = pd.DataFrame(topic_table)
st.dataframe(
    df_topic_display,
    use_container_width=True,
    hide_index=True,
    height=400,
)
st.caption(f"Showing top {len(topic_table)} topics by volume")

# =============================================================================
# Section 6: Topics (Topic Modeling)
# =============================================================================
st.markdown("---")
st.markdown("## üß¨ Topics (Topic Modeling)")
st.markdown("""
These topics were identified through a bottom-up approach: key themes were extracted from publication abstracts 
using a deep learning‚Äìbased topic modelling method (BERTopic) and subsequently grouped into coherent clusters using k-means. 
Unlike the OpenAlex taxonomy, this data-driven approach makes it possible to identify cross-disciplinary patterns
and emerging research themes that may not be captured by traditional, predefined classification schemes.
""")

df_research = df_overview[df_overview["level"] == "tm_topic"].copy()
df_research["rt_id"] = df_research["id"].astype(int)
df_research = df_research.sort_values("pubs_total", ascending=False)

st.markdown("### Topics Overview")

rt_table = []
for _, row in df_research.iterrows():
    rt_table.append({
        "ID": row["rt_id"],
        "Topic": row["name"],
        "Pubs": int(row["pubs_total"]),
        "% Total": format_pct(row.get("pubs_pct_of_um", row.get("pubs_pct_of_ul"))),
        "% Int'l": format_pct(row.get("pct_international")),
        "% Company": format_pct(row.get("pct_company")),
        "% SDG": format_pct(row.get("pct_sdg")),
        "CAGR": format_cagr(row.get("cagr_2020_2024", row.get("cagr_2019_2023"))),
    })

df_rt_display = pd.DataFrame(rt_table)
st.dataframe(
    df_rt_display,
    use_container_width=True,
    hide_index=True,
    height=400,
)

# Heatmap: Topics x Domains
st.markdown("### Topics √ó Domains Heatmap")

st.markdown("""
This heatmap shows how each topic distributes across the four scientific domains.
Darker cells indicate higher publication counts. Topics spanning multiple domains reveal interdisciplinary research.
Toggle normalization to see the relative distribution within each topic rather than absolute counts.
""")

heatmap_data = []
for _, row in df_research.iterrows():
    dom_counts = parse_pubs_per_domain(row.get("pubs_per_domain", ""))
    heatmap_data.append({
        "Topic": row["name"],
        "rt_id": row["rt_id"],
        **{domain_id2name.get(d, f"Domain {d}"): dom_counts.get(d, 0) for d in DOMAIN_ORDER}
    })

df_heatmap = pd.DataFrame(heatmap_data)

df_heatmap["total"] = df_heatmap[[domain_id2name.get(d) for d in DOMAIN_ORDER]].sum(axis=1)
df_heatmap = df_heatmap.sort_values("total", ascending=True).tail(30)

normalize = st.checkbox("Normalize by row (show domain distribution per topic)", value=False)

domain_cols = [domain_id2name.get(d) for d in DOMAIN_ORDER]
z_values = df_heatmap[domain_cols].values.astype(float)

if normalize:
    row_sums = z_values.sum(axis=1, keepdims=True)
    row_sums[row_sums == 0] = 1
    z_values_normalized = z_values / row_sums
    
    hover_text = []
    for i, row_label in enumerate(df_heatmap["Topic"].tolist()):
        row_hover = []
        for j, col in enumerate(domain_cols):
            pct = z_values_normalized[i, j] * 100
            count = int(z_values[i, j])
            row_hover.append(f"{row_label}<br>{col}: {pct:.1f}% ({count} pubs)")
        hover_text.append(row_hover)
    
    fig_heatmap = go.Figure(data=go.Heatmap(
        z=z_values_normalized,
        x=domain_cols,
        y=df_heatmap["Topic"].tolist(),
        colorscale="Blues",
        hoverinfo="text",
        text=hover_text,
        zmin=0,
        zmax=1,
        colorbar=dict(tickformat=".0%"),
    ))
else:
    fig_heatmap = go.Figure(data=go.Heatmap(
        z=z_values,
        x=domain_cols,
        y=df_heatmap["Topic"].tolist(),
        colorscale="Blues",
        hovertemplate="<b>%{y}</b><br>%{x}: %{z:,} pubs<extra></extra>",
    ))

fig_heatmap.update_layout(
    height=max(500, len(df_heatmap) * 25),
    margin=dict(t=30, l=400, r=30, b=50),
    xaxis_title="Domain",
    yaxis_title="",
    yaxis=dict(
        tickmode="array",
        tickvals=list(range(len(df_heatmap))),
        ticktext=df_heatmap["Topic"].tolist(),
        automargin=True,
    ),
)

st.plotly_chart(fig_heatmap, use_container_width=True)

# =============================================================================
# Footer
# =============================================================================
st.markdown("---")
st.caption("Data: Otto-von-Guericke-Universit√§t Magdeburg publications 2020-2024 | OpenAlex + custom topic modeling")